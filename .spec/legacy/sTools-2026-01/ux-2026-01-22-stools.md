schema_version: 1
# UX Spec â€” sTools Core Validation Loop

## A) Mental model alignment
Users believe the tool scans a chosen skill tree, reports findings deterministically, and re-running after fixes yields consistent results. Evidence: README.md
We must reinforce that results are trustworthy, repeatable, and safe for CI usage with clear exit codes and stable outputs. Evidence: README.md
We must never imply that remote lifecycle operations are part of the MVP core validation loop or that validation is complete when errors remain. Evidence: docs/ExecPlan-CodexSkillManager.md

## B) Information architecture
Entities the user encounters include: Skill (SKILL.md file), Finding (validation issue), Rule (rule ID + severity), Agent (Codex/Claude), Root (skill tree directory), Scan (run event), and Report (exported output). Evidence: README.md
Navigation structure in the macOS app is mode-based: Validate/Check, Sync, Index, Security, Diagnostics, and Analytics (Stats) with a left-sidebar mode switch and a single active mode at a time. Evidence: README.md
Navigation boundaries: mode switching preserves filters and selection where possible but must not imply that a scan is still running after mode change. Evidence: README.md
CLI structure mirrors the app with commands for scan, sync-check, security, analytics, index, and logs, using consistent flags and exit codes. Evidence: README.md

## C) Affordances & actions
Validate/Check view: clickable run/rescan actions, filters for severity/agent/rule, context actions to open files, apply fixes, and add to baseline; any file-writing action must require explicit user confirmation and provide an undo-safe path. Evidence: README.md
Validate/Check view: when fix is available, the UI should clearly label auto vs manual fixes and show a preview before apply. Evidence: docs/FEATURE_IMPLEMENTATION.md
Sync view: clickable sync-check run, selection of roots, and detail panes for diffs; destructive actions are limited to user-confirmed copy/resolve operations (if enabled), with clear target root and overwrite warnings. Evidence gap: UI specifics not documented for copy actions.
Index view: clickable generate/update action, optional version bump, and export status; destructive actions are limited to write/update of Skills.md with confirmation and version bump summary. Evidence: README.md
Security view: clickable scan action and export options (JSON/SARIF); destructive actions are none, output is report-only, and findings must not redact away critical context. Evidence: README.md
Diagnostics view: clickable bundle export with options (include logs, time range), confirmation before writing ZIP files, and clear disclosure of redaction. Evidence: README.md
CLI affordances: command flags with explicit defaults, `--help` guidance, and `--format` for machine output; destructive actions require explicit flags (e.g., `--write`, `--bump`, `--fail-on-error`). Evidence: README.md

## D) System feedback states
Validate/Check: empty state when no SKILL.md files found (with `--allow-empty` guidance), loading state during scan, error state with per-finding details, and partial state when filters are applied. Evidence: README.md
Validate/Check: permission/auth state is not expected, but file-access failures must surface actionable paths (missing permissions, invalid roots). Evidence: README.md
Sync: empty state when trees match, loading state while diffing, error state on invalid roots or read failures, and conflict state when differences require user action. Evidence: docs/usage.md
Index: empty state when no skills found, loading state while generating index, error state on write failures, and success state with version bump summary. Evidence: README.md
Security: empty state when no findings, loading state during scan, error state on scanning failures, and export confirmation states. Evidence: README.md
Diagnostics: loading state with progress indicator, error state for bundle size/permission limits, and success state with output path shown. Evidence: README.md
CLI: clear exit codes (0 success, 1 validation errors, 2 usage errors), and explicit stderr messages for failures. Evidence: README.md

## E) UX acceptance criteria (testable)
Given a repo with valid skills, when a user runs a scan, then the UI/CLI shows zero errors and a success exit code. Evidence: README.md
Given a repo with validation errors, when a user applies an auto-fix and re-runs the scan, then the error count decreases or resolves without introducing new errors. Evidence: docs/FEATURE_IMPLEMENTATION.md
Given Codex and Claude roots with drift, when a user runs sync-check, then the UI/CLI lists only-in-Codex, only-in-Claude, and mismatched items. Evidence: docs/usage.md
Given a skill with unsafe patterns, when a user runs security scan, then findings are reported and can be exported to SARIF or JSON. Evidence: README.md
Given a support request, when a user exports a diagnostics bundle, then the ZIP contains findings, events, and system info with redaction. Evidence: README.md

## Evidence Gaps
- Detailed UI affordances for destructive sync/resolve actions are not documented. Evidence gap: No UI doc found.
- Precise navigation structure for all app modes is implied but not explicitly mapped. Evidence gap: No IA diagram found.

## Evidence Map
| Evidence | Description | Why used |
| --- | --- | --- |
| README.md | Product features, modes, CLI usage, exit codes | IA, affordances, states, AC |
| docs/usage.md | CLI usage and sync behaviors | Sync states + AC |
| docs/FEATURE_IMPLEMENTATION.md | Fix workflow UX | AC for fixes |
| docs/ExecPlan-CodexSkillManager.md | Out-of-scope remote parity | Mental model guardrail |
